{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE Bayes algorithm\n",
    "\n",
    "Naive Bayes Algorithm is a classification algorithm based on Bayes Theorem. It is called naive because it assumes that the features in a dataset are independent of each other. This assumption is not true in real life but it simplifies the computation and gives good results in most of the cases.\n",
    "\n",
    "- It is a probabilistic Machine Learning Model.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "Bayes Theorem is a mathematical formula used for calculating conditional probability. It is defined as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where A and B are events and P(B) != 0\n",
    "\n",
    "#### Law of Total Probability\n",
    "\n",
    "$$P(B) = P(B|A) P(A) + P(B|~A) P(~A)$$\n",
    "\n",
    "## Naive Bayes Algorithm\n",
    "\n",
    "Naive Bayes Algorithm is based on Bayes Theorem. It is defined as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1,x_2,...,x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "where y is the class variable and x1, x2, ..., xn are the features.\n",
    "\n",
    "The algorithm assumes that the features are independent of each other. So, the above equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1|y)P(x_2|y)...P(x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "The denominator is constant for a given input. So, the equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) \\propto P(x_1|y)P(x_2|y)...P(x_n|y)P(y)$$\n",
    "\n",
    "The class with the highest probability is the output of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of NB Classifiers\n",
    "\n",
    "1. Gaussian Naive Bayes: Used when features are continuous and normally distributed.\n",
    "2. Multinomial Naive Bayes: Often used for document classification, where the features are the frequencies of the words or tokens in the documents.\n",
    "3. Bernoulli Naive Bayes: Used when features are binary (Os and 1s).\n",
    "\n",
    "## Applications\n",
    "\n",
    "1. Email Spam Filtering\n",
    "2. Setiment Analysis\n",
    "3. Document Categorization\n",
    "4. Medical Diagnosis\n",
    "\n",
    "- Particulary useful in `classification tasks`.\n",
    "- Simple Algorithm.\n",
    "- Efficient.\n",
    "- Very fast.\n",
    "- Good Performance.\n",
    "\n",
    "`Limitations`\n",
    "- Feature Independence\n",
    "  - Requires feature independence\n",
    "- Data Scarcity\n",
    "- Highly Correlated Features\n",
    "  - Not perform well when highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# train test split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9777777777777777\n",
      "Confusion Matrix: \n",
      " [[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9555555555555556\n",
      "Confusion Matrix: \n",
      " [[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 12]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# train the model\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.28888888888888886\n",
      "Confusion Matrix: \n",
      " [[ 0 19  0]\n",
      " [ 0 13  0]\n",
      " [ 0 13  0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.29      1.00      0.45        13\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.29        45\n",
      "   macro avg       0.10      0.33      0.15        45\n",
      "weighted avg       0.08      0.29      0.13        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khan\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\khan\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\khan\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# model initialize\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# train the model\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
